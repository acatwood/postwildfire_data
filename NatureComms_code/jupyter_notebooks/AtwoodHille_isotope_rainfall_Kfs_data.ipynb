{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da43c431",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "import scipy\n",
    "from scipy import stats\n",
    "from scipy.optimize import curve_fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1c0fe6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#I#SOTOPE DATA##\n",
    "#read in isotope data and turn it into pandas dataframe\n",
    "SG_water=pd.read_csv('/path/to/file/SGiso.csv')\n",
    "df=pd.DataFrame(SG_water)\n",
    "sns.set_theme(style=\"white\")\n",
    "\n",
    "#set timestamp, calculate d-excess, group data by sample type, streams and storm number\n",
    "df['timestamp']=df['Date']+' '+df['Time']\n",
    "df['date_time']=pd.to_datetime(df['timestamp'])\n",
    "df['d-excess']=df['ð›¿D']-8*df['ð›¿18O']\n",
    "streams=df.loc[df['Sample Type'] == 'Stream']\n",
    "rain=df.loc[df['Sample Type'] == 'Rain']\n",
    "intrain=df.loc[df['Sample Type'] == 'Integrated Rain']\n",
    "storm1=df.loc[df['Storm'] =='storm 1']\n",
    "storm2=df.loc[df['Storm'] =='storm 2']\n",
    "storm3=df.loc[df['Storm'] =='storm 3']\n",
    "storm4=df.loc[df['Storm'] =='storm 4']\n",
    "storm5=df.loc[df['Storm'] =='storm 5']\n",
    "storm6=df.loc[df['Storm'] =='storm 6']\n",
    "storm7=df.loc[df['Storm'] =='storm 7']\n",
    "df_sorted=df.sort_values(by='date_time')\n",
    "\n",
    "#make custom color map by location\n",
    "colors=['#F26513','#F2921D', '#019966' ]\n",
    "locations=['Louise','Thelma', 'Henry']\n",
    "cmap=dict(zip(locations, colors))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75e8e5cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "##RAINFALL DATA##\n",
    "#read in rainfall data and turn it into pandas dataframe\n",
    "precip=pd.read_csv('/path/to/data/Bobat_Fire_Rain_Gauge_Louise.csv')\n",
    "precip=pd.DataFrame(precip)\n",
    "\n",
    "#set date time and other titles\n",
    "precip['date_time']=pd.to_datetime(precip['Date and Time'])\n",
    "precip['rain_units']=precip['Rainfall units']\n",
    "precip['cum_rain_cm']=precip['Cumulative Rainfall  (cm) ']\n",
    "precip['rain_cm']=precip['Rainfall (cm)']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "760d4543",
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate average precipitation weighted isotopic value for each storm\n",
    "storm1['weightediso']=(storm1['ð›¿18O']*storm1['Rain (cm)'])/(storm1['Rain (cm)'].sum())\n",
    "s1pw18O=storm1['weightediso'].sum()\n",
    "storm2['weightediso']=(storm2['ð›¿18O']*storm2['Rain (cm)'])/(storm2['Rain (cm)'].sum())\n",
    "s2pw18O=storm2['weightediso'].sum()\n",
    "storm3['weightediso']=(storm3['ð›¿18O']*storm3['Rain (cm)'])/(storm3['Rain (cm)'].sum())\n",
    "s3pw18O=storm3['weightediso'].sum()\n",
    "storm4['weightediso']=(storm4['ð›¿18O']*storm4['Rain (cm)'])/(storm4['Rain (cm)'].sum())\n",
    "s4pw18O=storm4['weightediso'].sum()\n",
    "storm5['weightediso']=(storm5['ð›¿18O']*storm5['Rain (cm)'])/(storm5['Rain (cm)'].sum())\n",
    "s5pw18O=storm5['weightediso'].sum()\n",
    "storm6['weightediso']=(storm6['ð›¿18O']*storm6['Rain (cm)'])/(storm6['Rain (cm)'].sum())\n",
    "s6pw18O=storm6['weightediso'].sum()\n",
    "storm7['weightediso']=(storm7['ð›¿18O']*storm7['Rain (cm)'])/(storm7['Rain (cm)'].sum())\n",
    "s7pw18O=storm7['weightediso'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dffb78b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Calculate relationship between rainfall intensity, Fnew and Kfs values##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e2ffe0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Fnew## \n",
    "#resample rainfall data for every 30 minutes, change units to mm/hr and find log rainfall\n",
    "precip_30=pd.DataFrame()\n",
    "precip_30['rain_cm']=precip.rain_cm.resample('30min', closed=\"left\", label='right', origin='start').sum()\n",
    "precip_30['rain_mm']=precip_30['rain_cm']*10\n",
    "precip_30['rain_mmhr']=precip_30['rain_mm']*4\n",
    "precip_30['rain_mmhr']=precip_30['rain_mmhr'].replace(0,np.nan)\n",
    "precip_30['log_rain_mmhr']=  np.log10(precip_30['rain_mmhr'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c39aeb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "##read in fnew isotope data, add timstamp and locate storms with Fnew values ##\n",
    "fnew=pd.read_csv('/path/to/data/AtwoodHille_SanGabes_Fnew_isotopes.csv')\n",
    "fnew['timestamp']=fnew['Date']+' '+fnew['Time']\n",
    "fnew['date_time']=pd.to_datetime(fnew['timestamp'])\n",
    "fnew=fnew.set_index('date_time')\n",
    "storm4_fnew=fnew.loc['2021-12-14':'2021-12-15']\n",
    "storm4_fnew=storm4_fnew.sort_values(by='date_time')\n",
    "storm5_fnew=fnew.loc['2021-12-23':'2021-12-24']\n",
    "storm5_fnew=storm5_fnew.sort_values(by='date_time')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0afc8b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Kfs Values ##\n",
    "#read in Kfs values\n",
    "SG_Ks=pd.read_csv('/path/to/data/Ks_results.csv')\n",
    "Ks=pd.DataFrame(SG_Ks)\n",
    "\n",
    "##replace 0 infiltration with extremely low infiltration rate for log conversion \n",
    "Ks.replace(0,0.000001,inplace=True)\n",
    "\n",
    "#drop values higher than 3 standard deviation based on z-score\n",
    "z = np.abs(stats.zscore(Ks['Ks (mm/hr)']))\n",
    "print(np.where(z>3))\n",
    "Ks=Ks.drop([25])\n",
    "#calculate log of Ks values\n",
    "Ks['log_ks_mmhr']= np.log10(Ks['Ks (mm/hr)'])\n",
    "z = np.abs(stats.zscore(Ks['log_ks_mmhr']))\n",
    "print(np.where(z > 3))\n",
    "\n",
    "#separate data by catchment\n",
    "henry=Ks.loc[Ks['Location']== 'Henry']\n",
    "louise=Ks.loc[Ks['Location']== 'Louise']\n",
    "thelma=Ks.loc[Ks['Location']== 'Thelma']\n",
    "#find median log kfs values in mm/hr\n",
    "HKfs=henry['log_ks_mmhr'].median()\n",
    "LKfs=louise['log_ks_mmhr'].median()\n",
    "\n",
    "#calculate the 30 min precipitation intensity devided by the median log kfs value at each catchment\n",
    "precip_30['rain_intens/Lkfs']= precip_30['log_rain_mmhr']/LKfs\n",
    "precip_30['rain_intens/Hkfs']= precip_30['log_rain_mmhr']/HKfs\n",
    "\n",
    "#locate 30minute precip data for storms with calculable Fnew values  \n",
    "storm4_precip=precip_30.loc['2021-12-14':'2021-12-15']\n",
    "storm5_precip=precip_30.loc['2021-12-23':'2021-12-24']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ace3307",
   "metadata": {},
   "outputs": [],
   "source": [
    "#merge storm precipitation and storm fnew value based on date time\n",
    "#for storm 4\n",
    "merged=pd.merge_asof(storm4_fnew, storm4_precip, on=\"date_time\", direction=\"nearest\")\n",
    "louise_merged=merged.loc[merged['Location'] =='Louise']\n",
    "henry_merged=merged.loc[merged['Location'] =='Henry']\n",
    "#for storm 5\n",
    "merged2=pd.merge_asof(storm5_fnew, storm5_precip, on=\"date_time\", direction=\"nearest\")\n",
    "louise_merged2=merged2.loc[merged2['Location'] =='Louise']\n",
    "henry_merged2=merged2.loc[merged2['Location'] =='Henry']\n",
    "#drop any non number values from the four datasets\n",
    "henry_merged2=henry_merged2.dropna()\n",
    "louise_merged2=louise_merged2.dropna()\n",
    "henry_merged=henry_merged.dropna()\n",
    "louise_merged=louise_merged.dropna()\n",
    "#combine locational datasets\n",
    "louise=pd.concat([louise_merged,  louise_merged2])\n",
    "henry=pd.concat([henry_merged, henry_merged2])\n",
    "#drop outliers\n",
    "merged=pd.concat([louise, henry])\n",
    "z = np.abs(stats.zscore(merged['Fnew']))\n",
    "print(np.where(z > 3))\n",
    "merged.drop(merged.index[[37, 48, 49, 52]], inplace=True)\n",
    "\n",
    "#separate datasets by location after droping outliers\n",
    "henry_merged=merged.loc[merged['Location'] =='Henry']\n",
    "louise_merged=merged.loc[merged['Location'] =='Louise']\n",
    "louise_merged['Kfs_reg']=louise_merged['rain_intens/Lkfs']\n",
    "henry_merged['Kfs_reg']=henry_merged['rain_intens/Hkfs']\n",
    "merged=pd.concat([louise_merged, henry_merged])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d43aa32b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate function to fit for linear regression:\n",
    "def fit_func(x, m, b):\n",
    "    return (m*x) + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "314349f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate linear regression of rainfall intenisty/kfs vs Fnew\n",
    "# model fit on full sample of data:\n",
    "Fpars, Fcov = curve_fit(f=fit_func, xdata=merged['Kfs_reg'], ydata=merged['Fnew']) \n",
    "# Get the axis limits\n",
    "left, right = ax.get_xlim()\n",
    "bottom, top = ax.get_ylim()\n",
    "\n",
    "# get x axis limits\n",
    "xlim = plt.xlim()\n",
    "# fitted plot values (for CI)\n",
    "x_fitted = (merged['Kfs_reg'])\n",
    "y_fitted = fit_func(x_fitted, *Fpars)\n",
    "\n",
    "residuals=(merged['Fnew']-y_fitted)\n",
    "ss_res=np.sum(residuals**2)\n",
    "ss_tot=np.sum((merged['Fnew']-np.mean(merged['Fnew']))**2)\n",
    "r_squared=1-(ss_res/ss_tot)\n",
    "print(r_squared)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
